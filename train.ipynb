{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch ver:  2.0.0\n",
      "image shape:  torch.Size([1, 28, 28])\n",
      "# labels:  10\n",
      "{'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "print('torch ver: ', torch.__version__)\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),]) \n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "image, label = trainset[0] \n",
    "print(\"image shape: \", image.shape) # torch.Size([1, 28, 28])\n",
    "print(\"# labels: \", len(testset.classes))\n",
    "print(testset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 50000, Validation set size: 10000, Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Final sizes are 50000, 10000, 10000\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [50000, 10000])\n",
    "print(f'Train set size: {len(trainset)}, Validation set size: {len(valset)}, Test set size: {len(testset)}')\n",
    "# Shuffle the data at the start of each epoch (only useful for training set)\n",
    "batchsize = 128 # was 32\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batchsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "_K = 10\n",
    "dedup_train_loader = torch.load(f'./loaders/fmnist/dedup_train@k={_K}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dense model...\n",
      "Epoch 0: loss=0.5893656015396118\n",
      "Epoch 1: loss=0.2995685935020447\n",
      "Epoch 2: loss=0.3366810381412506\n",
      "Epoch 3: loss=0.3461603820323944\n",
      "Epoch 4: loss=0.45827823877334595\n",
      "Epoch 5: loss=0.3244563639163971\n",
      "Epoch 6: loss=0.37949681282043457\n",
      "Epoch 7: loss=0.19144146144390106\n",
      "Epoch 8: loss=0.14109563827514648\n",
      "Epoch 9: loss=0.21466879546642303\n",
      "Training dedup model...\n",
      "Epoch 0: loss=0.5624696612358093\n",
      "Epoch 1: loss=0.3399209976196289\n",
      "Epoch 2: loss=0.5185234546661377\n",
      "Epoch 3: loss=0.603087306022644\n",
      "Epoch 4: loss=0.27909615635871887\n",
      "Epoch 5: loss=0.540800929069519\n",
      "Epoch 6: loss=0.321259468793869\n",
      "Epoch 7: loss=0.4345487952232361\n",
      "Epoch 8: loss=0.3049241006374359\n",
      "Epoch 9: loss=0.3929382264614105\n",
      "Dense training time: 38.63566780090332\n",
      "Dedup training time: 7.133240222930908\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils.engine import *\n",
    "from utils.models import myMLP\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "# shared hparams\n",
    "device = 'mps'\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def driver(loader, mode):\n",
    "    print(f\"Training {mode} model...\")\n",
    "    model = myMLP().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    trained_model = train(model, loader, optimizer,\n",
    "                loss_fn, device=device, epochs=epochs)\n",
    "    \n",
    "    return trained_model\n",
    "\n",
    "# 'dense' or 'dedup'\n",
    "_MODE = 'dense' \n",
    "start = time.time()\n",
    "dense_model = driver(train_loader, mode=_MODE)\n",
    "end = time.time()\n",
    "dense_time = end - start\n",
    "\n",
    "_MODE = 'dedup'\n",
    "start = time.time()\n",
    "dedup_model =driver(dedup_train_loader, mode=_MODE)\n",
    "end = time.time()\n",
    "dedup_time = end - start\n",
    "\n",
    "print(f\"Dense training time: {dense_time}\")\n",
    "print(f\"Dedup training time: {dedup_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.88 (original), 0.86 (deduplicated)\n",
      "Training Speedup = 5.42x\n"
     ]
    }
   ],
   "source": [
    "dense_acc = evaluate(dense_model, test_loader, device=device)\n",
    "dedup_acc = evaluate(dedup_model, test_loader, device=device)\n",
    "print(f\"Accuracy on test set: {dense_acc:.2f} (original), {dedup_acc:.2f} (deduplicated)\")\n",
    "print(f'Training Speedup = {dense_time / dedup_time:.2f}x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TRIAL 2\\nAccuracy on test set: 0.88 (original), 0.87 (deduplicated)\\nDense training time: 38.01654291152954\\nDedup training time: 7.568618059158325\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' TRIAL 1\n",
    "Accuracy on test set: 0.88 (original), 0.85 (deduplicated)\n",
    "Dense training time: 38.458457708358765\n",
    "Dedup training time: 8.423368215560913\n",
    "'''\n",
    "\n",
    "''' TRIAL 2\n",
    "Accuracy on test set: 0.88 (original), 0.87 (deduplicated)\n",
    "Dense training time: 38.01654291152954\n",
    "Dedup training time: 7.568618059158325\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "499",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
